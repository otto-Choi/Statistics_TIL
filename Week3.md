# 통계학 3주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_3rd_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

3주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다


## Statistics_3rd_TIL

### 2부. 데이터 분석 준비하기

### 08. 분석 프로젝트 준비 및 기획

### 09. 분석 환경 세팅하기



## Study ScheduleStudy Schedule

| 주차  | 공부 범위     | 완료 여부 |
| ----- | ------------- | --------- |
| 1주차 | 1부 p.2~46    | ✅         |
| 2주차 | 1부 p.47~81   | ✅         |
| 3주차 | 2부 p.82~120  | ✅         |
| 4주차 | 2부 p.121~167 | 🍽️         |
| 5주차 | 2부 p.168~202 | 🍽️         |
| 6주차 | 3부 p.203~250 | 🍽️         |
| 7주차 | 3부 p.251~299 | 🍽️         |

<!-- 여기까진 그대로 둬 주세요-->



# 1️⃣ 개념 정리 

## 08. 분석 프로젝트 준비 및 기획

```
✅ 학습 목표 :
* 데이터 분석 프로세스를 설명할 수 있다.
* 비즈니스 문제를 정의할 때 주의할 점을 설명할 수 있다.
* 외부 데이터를 수집하는 방법에 대해 인식한다.
```
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

&ensp;
데이터분석의 궁극적인 목표는 의사결정 프로세스를 최적화하는 것이다. 즉, 보다 효과적인 결정을 할 수 있도록 도움을 주는 것이 데이터 분석의 주된 목적이다.
<hr/>

1. 기본적인 데이터 분석의 전체 프로세스
    1. 설계 단계
        - 데이터 분석에 들어가기에 앞서 무엇을 하고자 하는지를 명확히 정의하고 프로젝트를 수행할 인력을 구성
    2. 분석 및 모델링 단계
        - 데이터 분석 및 모델링을 위한 서버 환경을 마련하고 본격적인 데이터 분석과 모델링을 수행
    3. 구축 및 활용 단계
        - 최종적으로 선정된 분석 모델을 실제 업무에 적용하고 그 성과를 측정
2. CRISP-DM 방법론
    1. 비즈니스 이해
    2. 데이터 이해
    3. 데이터 준비
    4. 모델링
    5.  평가
    6. 베포
3. SAS SEMMA 방법론
    1. Sampling 단계
    2. Exploration 단계
    3. Modification 단계
    4. Modeling 단계
    5. Assessment 단계
4. 보편적인 흐름
    1. 초반부: 비즈니스 문제와 해결 방향을 명확히 정의하고 데이터를 탐색
    2. 중반부: 데이터를 목적에 맞도록 수집 및 가공하고 필요에 따라 머신러닝 모델을 활용
    3. 후반부: 데이터 분석 결과를 검토 및 검증하고 실제 환경에 적용
<hr/>

&ensp;
성공적인 데이터 분석 프로젝트를 위해서는 프로젝트를 시작하기 전에 현재의 문제를 명확하게 정의하고, 그에 맞는 데이터 분석 목적을 설정해야 한다. 중요한 점은 비즈니스 문제는 항상 현상에 대한 설명으로 끝나서는 안되고, 본질적인 문제점이 함께 전달되어야 하는 것이다.
<hr/>
&ensp;
분석 프로젝트의 방향이 언제나 바뀔 수 있다는 점을 염두에 두어야 한다. 콘셉트가 바뀌는 순간 이를 확실하게 인지하고 신속하게 모든 팀원, 실무자들과 공유해야 한다. 
<hr/>
도메인 지식: 해당되는 분야에 업에 대한 이해도<br>
&ensp; 비즈니스 도메인을 이해하는 것은 곧 데이터 분석가의 전문 역량을 갖추는 것이라 할 수 있다. 왜냐하면 직접 의미 있는 변수를 찾아내고 분석 방향을 설정하는 것은 도메인 지식이 충분하게 수반됐을 때 가능하기 때문이다.
<hr/>
&ensp; 데이터를 수집하기 전에 분석 목적을 명확히 정의하고, 이에 맞는 외부 데이터를 찾고 수집해야 한다. 찾고 수집하는 과정에서 크롤링을 활용할 때는 법적인 이슈도 함께 고려해야 한다.

- 크롤링과 스크래핑: Web상을 돌아다니면서 정보를 수집하는 것
    - 크롤링: 웹 페이지가 주어지면 그 페이지 내에 있는 링크들을 따라가면서 모든 내용을 다 가져오는 것
    - 스크래핑: 웹 페이지에서 자신이 원하는 부분의 정보만 가져오는 것


## 09. 분석 환경 세팅하기

```
✅ 학습 목표 :
* 데이터 분석의 전체적인 프로세스를 설명할 수 있다.
* 테이블 조인의 개념과 종류를 이해하고, 각 조인 방식의 차이를 구분하여 설명할 수 있다.
* ERD의 개념과 역할을 이해하고, 기본 구성 요소와 관계 유형을 설명할 수 있다.
```

<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->


||SAS|R|파이썬|
|---|---|---|---|
|장점|높은 신뢰도<br>GUI 지원을 통한 쉬운 사용 환경<br>**공식 서비스 지원 제공**|무료 오픈소스<br>**방대한 라이브러리와 커뮤니티**<br>최신 방법론의 빠른 적용 및 패치|무료 오픈소스<br>방대한 라이브러리와 커뮤니티<br>**프로그래밍 기반의 다양한 사용성**|
|단점|높은 라이선스 비용<br>딥러닝 등 신기술에 대한 늦은 적용|가파른 학습 곡선<br>유저 인터페이스 미지원<br>공식 서비스 지원 없음|프로그래밍 기반의 지식 필요<br>높은 라이선스 비용<br>딥러닝 등 신기술에 대한 늦은 적용<br>느린 속도|
<br><br>
<hr/>
데이터 처리 프로세스

- OLTP(On-Line Transaction Processing): 실시간으로 데이터를 트랜잭션 단위로 수집, 분류, 저장하는 시스템
- DW(Data Warehouse): 수집된 데이터를 사용자 관점에서 주제별로 통합하여 쉽게 원하는 데이터를 빼낼 수 있도록 저장해 놓은 통합 데이터베이스
- ODS(Operational Data Store): DW에 저장하기 전에 임시로 데이터를 보관하는 중간 단계의 저장소
- DM(Data Mart): 사용자의 목적에 맞도록 가공된 일부의 데이터가 저장되는 곳으로, 부서나 사용자 집단에 필요에 맞도록 개별 데이터 저장소
- ETL(Extract-Transform-Load): 저장된 데이터를 사용자가 요구하는 포맷으로 변형하여 이동시키는 과정

<hr/>

 분산 데이터 처리: 한 컴퓨터가 처리해야 할 일을 여러 컴퓨터가 나눠서 한 다음 그 결과를 합치는 것
- Scale-up 방식: 하나의 컴퓨터의 용량을 늘리고 더 빠른 프로세서를 탑재하는 방법
- Scale-out 방식: 분산데이터 처리처럼 여러 대의 컴퓨터를 병렬적으로 연결하는 것

분산 데이터 처리 기술
- HDFS: Hadoop Distributed File System: 구글이 처음 고안
    - 슬레이브 노드(Slave node): 데이터를 저장하고 계산하는 세부적인 역할 수행
    - 마스터 노드(Master node): 대량의 데이터를 HDFS에 저장하고 맵리듀스 방식을 통해 데이터를 병렬 처리
    - 클라이언트 머신(Client machines): 맵리듀스 작업을 통해 산출된 결과를 보여주는 역할
- 맵리듀스: 구글에서 발표한 논문을 바탕으로 아파치 오픈소스 프로젝트에서 개발됨
    - 맵(Map): 흩어져 있는 데이터를 관련된 데이터끼리 묶어서 임시의 집합을 만드는 과정
    - 리듀스(Reduce): 필터링과 정렬을 걸쳐 데이터를 뽑아내는 과정
    - 중요 특징: key-value 쌍으로 데이터를 처리한다.
- 하둡의 버전
    - 하둡 1.0: HDFS | 맵리듀스 | 데이터 프로세싱
    - 하둡 2.0: HDFS | YARN | 맵리듀스, 데이터 프로세싱, SQL, 기타
- 아파치 스파크

<hr/>

테이블 조인: 2개 이상의 테이블을 공통의 칼럼을 중심으로 결합하는 것
- 이너 조인
- 아우터 조인
- 레프트 조인
- 라이트 조인
- 풀 조인
- 크로스 조인: 값이 없더라도 모든 행이 생기도록 가공을 해야 할 때 크로스 조인을 사용한다. 

데이터 단어사전: 각 칼럼과 테이블의 이름을 정할 때 체계를 약속한 일종의 사전<br>
메타데이터 관리 시스템: 데이터가 어디에 어떻게 저장되어 있는지, 그리고 데이터를 어떻게 사용할 것인지 이해할 수 있도록 데이터에 대한 정보를 관리하는 시스템<br>
테이블 정의서: DW, DM 등에 적재된 테이블과 칼럼의 한글과 영문명, 데이터 속성, 그리고 간단한 설명 등이 정리된 표<br>
ERD(Entity Relationship Diagram): 각 테이블의 구성 정보와 테이블 간 관계를 도식으로 표현한 그림



<br>
<br>

---

# 2️⃣ 확인 문제

## 문제 1.

> **🧚 아래의 테이블을 조인한 결과를 출력하였습니다. 어떤 조인 방식을 사용했는지 맞춰보세요.**

> 사용한 테이블은 다음과 같습니다.

| **emp_cd** | **emp_nm** | **job** | **dep_cd** |
| ---------- | ---------- | ------- | ---------- |
| 1001       | 김권택     | 부장    | 30         |
| 1002       | 김미정     | 과장    | 20         |
| 1003       | 이지민     | 대리    | 20         |
| 1004       | 장동혁     | 사원    | 10         |
| 1005       | 이승화     | 사원    | 30         |
| 1006       | 곽주영     | 과장    | 40         |
| 1007       | 조용호     | 사장    | NULL       |
| 1008       | 가나다     | 대리    | 40         |
| 1009       | 홍길동     | 차장    | 10         |

| **dep_cd** | **dep_nm** | **location** |
| ---------- | ---------- | ------------ |
| 10         | 인사팀     | 서울         |
| 20         | 경리팀     | 서울         |
| 30         | 영업팀     | 과천         |
| 40         | 전산팀     | 대전         |
| 50         | 법무팀     | 인천         |

> 보기: INNER, LEFT, RIGHT 조인

<!-- 테이블 조인의 종류를 이해하였는지 확인하기 위한 문제입니다. 각 테이블이 어떤 조인 방식을 이용하였을지 고민해보고 각 테이블 아래에 답을 작성해주세요.-->

### 1-1. 

| **emp_cd** | **emp_nm** | **job** | **dep_cd** | **dep_nm** | **location** |
| ---------- | ---------- | ------- | ---------- | ---------- | ------------ |
| 1001       | 김권택     | 부장    | 30         | 영업팀     | 과천         |
| 1002       | 김미정     | 과장    | 20         | 경리팀     | 서울         |
| 1003       | 이지민     | 대리    | 20         | 경리팀     | 서울         |
| 1004       | 장동혁     | 사원    | 10         | 인사팀     | 서울         |
| 1005       | 이승화     | 사원    | 30         | 영업팀     | 과천         |
| 1006       | 곽주영     | 과장    | 40         | 전산팀     | 대전         |
| 1007       | 김태연     | 사장    |            |            |              |
| 1008       | 최철원     | 대리    | 40         | 전산팀     | 대전         |
| 1009       | 노동희     | 차장    | 10         | 인사팀     | 서울         |

사원 정보의 테이블을 기준으로 부서 정보의 테이블에 대해 LEFT JOIN을 수행했다. NULL값을 가지는 1007 레코드를 제외하곤 모두 일치하는 부서의 정보가 [dep_cd]를 기준으로 조인 되었다. 한편, 부서 정보 테이블에 존재하는 50, 법무팀은 해당 값을 가지는 사원이 없어 조인된 테이블에 사용되지 않았다. 이를 통해 레프트 조인이 수행되었음을 알 수 있다.

<hr/>

### 1-2. 

| **emp_cd** | **emp_nm** | **job** | **dep_cd** | **dep_nm** | **location** |
| ---------- | ---------- | ------- | ---------- | ---------- | ------------ |
| 1001       | 김권택     | 부장    | 30         | 영업팀     | 과천         |
| 1002       | 김미정     | 과장    | 20         | 경리팀     | 서울         |
| 1003       | 이지민     | 대리    | 20         | 경리팀     | 서울         |
| 1004       | 장동혁     | 사원    | 10         | 인사팀     | 서울         |
| 1005       | 이승화     | 사원    | 30         | 영업팀     | 과천         |
| 1006       | 곽주영     | 과장    | 40         | 전산팀     | 대전         |
| 1008       | 최철원     | 대리    | 40         | 전산팀     | 대전         |
| 1009       | 노동희     | 차장    | 10         | 인사팀     | 서울         |

[dep_cd] 컬럼을 보았을 때, 각 테이블에 모두 존재하는 레코드만 표시된다. 즉, INNER JOIN이 수행되었다.

<hr/>

### 1-3. 

| **emp_cd** | **emp_nm** | **job** | **dep_cd** | **dep_nm** | **location** |
| ---------- | ---------- | ------- | ---------- | ---------- | ------------ |
| 1004       | 장동혁     | 사원    | 10         | 인사팀     | 서울         |
| 1009       | 홍길동     | 차장    | 10         | 인사팀     | 서울         |
| 1002       | 김미정     | 과장    | 20         | 경리팀     | 서울         |
| 1003       | 이지민     | 대리    | 20         | 경리팀     | 서울         |
| 1001       | 김권택     | 부장    | 30         | 영업팀     | 과천         |
| 1005       | 이승화     | 사원    | 30         | 영업팀     | 과천         |
| 1006       | 곽주영     | 과장    | 40         | 전산팀     | 대전         |
| 1008       | 최철원     | 대리    | 40         | 전산팀     | 대전         |
|            |            |         | 50         | 법무팀     | 인천         |

[dep_cd] 값이 NULL인 사원 테이블의 1007 데이터가 표시되지 않는 한편 사원 테이블의 [dep_cd]에 포함되지 않은 부서 테이블의 50, 법무팀이 출력되었다. 즉, RIGHT JOIN이 수행되었다.

<hr/>

별개로, 각 출력 결과에서 [emp_nm]이 기대된 값과 달리 나타난다. 

### 🎉 수고하셨습니다.
